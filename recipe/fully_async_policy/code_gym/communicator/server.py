from fastapi import FastAPI, Header, HTTPException, Body
from fastapi.responses import JSONResponse
import subprocess
import traceback
import shlex
import time
import re
import random
import os
from pathlib import Path
from dataclasses import dataclass, asdict
from typing import List, Dict, Optional, Any
import threading
from concurrent.futures import ThreadPoolExecutor, as_completed

# åˆå§‹åŒ–FastAPIåº”ç”¨
app = FastAPI(title="NUMA Bind Task Executor", version="1.0")

# ======================== æ ¸å¿ƒé…ç½® ========================
# 1. APIé‰´æƒKeyï¼ˆè°ƒç”¨æ–¹éœ€æºå¸¦ï¼‰
AUTH_API_KEY = "container-a-secure-key-2025"

# 2. å®‰å…¨é…ç½®ï¼šå…è®¸çš„åŸºç¡€å‘½ä»¤ï¼ˆç»‘æ ¸/é‡‡æ ·ç›¸å…³ï¼‰
ALLOWED_BASE_COMMANDS = {
    "numactl", "ps", "lscpu", "perf", "taskset", "kill", "grep", "top"
}

# 3. ä»»åŠ¡é˜Ÿåˆ—ï¼ˆFIFOï¼‰+ é”ï¼ˆä¿è¯çº¿ç¨‹å®‰å…¨ï¼‰
task_queue: List[Dict[str, Any]] = []
queue_lock = threading.Lock()
is_processing = False
completed_results: Dict[str, Any] = {}
processing_requests = set()
process_registry_lock = threading.Lock()
tracked_processes: Dict[int, "TrackedProcess"] = {}

# 4. NUMA/CPUåˆæ³•æ€§æ ¡éªŒæ­£åˆ™
NUMA_NODE_PATTERN = re.compile(r"^\d+$")  # æ•°å­—æ ¼å¼çš„NUMAèŠ‚ç‚¹
CPU_LIST_PATTERN = re.compile(r"^\d+(,\d+)*(-\d+)*$")  # æ”¯æŒ1,2,3 æˆ– 0-7æ ¼å¼
BENCHMARK_DIR = Path(__file__).resolve().parent.parent / "benchmarks"
BENCHMARK_BIN_DIR = BENCHMARK_DIR / "cpubench"
DISK_TEST_FILE = BENCHMARK_DIR / "disk_test.tmp"
TEST_DURATION = 1200
LOAD_COUNT_RANGE: Dict[str, tuple] = {
    "compute": (1, 5),
    "mem": (1, 8),
    "cache": (0, 5),
    "disk": (0, 5)
}
COMPUTE_THREADS = 48
MEM_THREADS = 48
MEM_SIZE_MB = 4096
MEM_GRANULARITY = 64
MEM_SEQUENTIAL = 0
CACHE_THREADS = 48
CACHE_SIZE_MB = 40
DISK_THREADS = 48
DISK_FILE_SIZE_MB = 1024
DISK_BLOCK_SIZE_KB = 8
DISK_SEQUENTIAL = 0
DISK_READ_ONLY = 0

# benchmark è¿›ç¨‹é‡‡æ ·ä¸´æ—¶æ–‡ä»¶ç›®å½•ï¼ˆç”± load_common.h å†™å…¥ï¼‰
CODEGYM_SAMPLE_DIR = Path(os.environ.get("CODEGYM_SAMPLE_DIR", "/tmp/codegym_samples"))
CODEGYM_SAMPLE_PREFIX = "sample_"
CODEGYM_SAMPLE_SUFFIX = ".log"

# ======================== æ•°æ®ç»“æ„å®šä¹‰ ========================
@dataclass
class BindCommandResult:
    """å•æ¡ç»‘æ ¸æŒ‡ä»¤çš„æ‰§è¡Œä¸é‡‡æ ·ç»“æœ"""
    command: str
    pid: Optional[int]
    bind_success: bool
    sample_results: Dict[str, Any]
    exit_code: int
    reward: Optional[Dict[str, Any]] = None
    error_msg: str = ""

@dataclass
class BindTaskResult:
    """ç»‘æ ¸ä»»åŠ¡ï¼ˆåŒ…å«å¤šæ¡æŒ‡ä»¤ï¼‰çš„æ•´ä½“ç»“æœ"""
    request_id: str
    success: bool
    command_results: List[BindCommandResult]
    reward: Optional[Dict[str, Any]] = None
    error_msg: str = ""


@dataclass
class TrackedProcess:
    """è®°å½•ç”±å½“å‰serverå¯åŠ¨çš„è¿›ç¨‹ï¼Œä¾¿äºç»Ÿä¸€åœæ­¢"""
    proc: subprocess.Popen
    command: str
    source: str
    start_time: float

# ======================== å·¥å…·å‡½æ•° ========================
def validate_numa_cpu(numa_node: str, cpu_list: str) -> bool:
    """æ ¡éªŒNUMAèŠ‚ç‚¹å’ŒCPUæ ¸å¿ƒæ˜¯å¦åˆæ³•ï¼ˆåŸºäºlscpuè¾“å‡ºï¼‰"""
    try:
        # æ ¡éªŒæ ¼å¼
        if not NUMA_NODE_PATTERN.match(numa_node):
            return False
        if not CPU_LIST_PATTERN.match(cpu_list):
            return False
        
        # æ ¡éªŒå®é™…å­˜åœ¨çš„NUMAèŠ‚ç‚¹
        lscpu_result = subprocess.run(
            ["lscpu"],
            stdout=subprocess.PIPE,
            stderr=subprocess.PIPE,
            encoding="utf-8"
        )
        numa_nodes = re.findall(r"NUMA node\(s\):\s+(\d+)", lscpu_result.stdout)
        if not numa_nodes or int(numa_node) >= int(numa_nodes[0]):
            return False
        
        # æ ¡éªŒCPUæ ¸å¿ƒèŒƒå›´ï¼ˆç®€åŒ–ç‰ˆï¼šä»…æ£€æŸ¥æœ€å¤§CPUæ•°ï¼‰
        cpu_max = re.findall(r"CPU\(s\):\s+(\d+)", lscpu_result.stdout)
        if not cpu_max:
            return False
        max_cpu = int(cpu_max[0]) - 1  # CPUç¼–å·ä»0å¼€å§‹
        # è§£æCPUåˆ—è¡¨ä¸­çš„æ‰€æœ‰æ ¸å¿ƒ
        cpu_parts = cpu_list.replace(",", "-").split("-")
        for cpu in cpu_parts:
            if cpu and int(cpu) > max_cpu:
                return False
        
        return True
    except Exception:
        return False

def execute_shell_command(cmd_parts: List[str], timeout: int = 10) -> Dict[str, str]:
    """
    æ‰§è¡Œå•ä¸ªshellå‘½ä»¤ï¼ˆå®‰å…¨æ¨¡å¼ï¼Œæ— shellæ³¨å…¥ï¼‰
    :param cmd_parts: å‘½ä»¤æ‹†åˆ†åˆ—è¡¨ï¼ˆå¦‚["ps", "-ef"]ï¼‰
    :param timeout: è¶…æ—¶æ—¶é—´
    :return: åŒ…å«stdout/stderr/exit_codeçš„å­—å…¸
    """
    try:
        # æ ¡éªŒåŸºç¡€å‘½ä»¤æ˜¯å¦åœ¨ç™½åå•
        if cmd_parts[0] not in ALLOWED_BASE_COMMANDS:
            return {
                "exit_code": -3,
                "stdout": "",
                "stderr": f"ç¦æ­¢æ‰§è¡Œå‘½ä»¤ï¼š{cmd_parts[0]}ï¼ˆä»…å…è®¸{ALLOWED_BASE_COMMANDS}ï¼‰"
            }
        
        result = subprocess.run(
            cmd_parts,
            stdout=subprocess.PIPE,
            stderr=subprocess.PIPE,
            timeout=timeout,
            encoding="utf-8",
            errors="ignore"
        )
        return {
            "exit_code": result.returncode,
            "stdout": result.stdout,
            "stderr": result.stderr
        }
    except subprocess.TimeoutExpired:
        return {
            "exit_code": -1,
            "stdout": "",
            "stderr": f"å‘½ä»¤æ‰§è¡Œè¶…æ—¶ï¼ˆ{timeout}ç§’ï¼‰"
        }
    except Exception as e:
        return {
            "exit_code": -2,
            "stdout": "",
            "stderr": f"å‘½ä»¤æ‰§è¡Œå¤±è´¥ï¼š{str(e)}"
        }

def _sample_file_for_pid(pid: int) -> Path:
    return CODEGYM_SAMPLE_DIR / f"{CODEGYM_SAMPLE_PREFIX}{pid}{CODEGYM_SAMPLE_SUFFIX}"


def get_tracked_pids() -> List[int]:
    cleanup_finished_processes()
    with process_registry_lock:
        return list(tracked_processes.keys())

def get_workload_processes() -> List[Dict[str, Any]]:
    """è¿”å›ç”± server å¯åŠ¨çš„ benchmark è´Ÿè½½è¿›ç¨‹ä¿¡æ¯ï¼ˆPID/å‘½ä»¤/æ¥æºï¼‰ã€‚"""
    cleanup_finished_processes()
    with process_registry_lock:
        items = [
            (pid, tracked)
            for pid, tracked in tracked_processes.items()
            if tracked.source.startswith("benchmark:")
        ]
    workloads: List[Dict[str, Any]] = []
    for pid, tracked in sorted(items, key=lambda it: it[0]):
        workloads.append(
            {
                "pid": pid,
                "command": tracked.command,
                "source": tracked.source,
                "start_time": tracked.start_time,
            }
        )
    return workloads


def _parse_perf_stat_csv(stderr_text: str) -> Dict[str, Optional[float]]:
    """è§£æ perf stat -x, è¾“å‡ºï¼Œè¿”å› event_name -> valueï¼ˆæ— æ³•è§£æåˆ™ä¸º None / ç¼ºå¤±ï¼‰"""
    counters: Dict[str, Optional[float]] = {}
    for line in stderr_text.splitlines():
        parts = [p.strip() for p in line.split(",")]
        if len(parts) < 3:
            continue
        value_str, _, event_name = parts[0], parts[1], parts[2]
        if not event_name or event_name == "time elapsed":
            continue
        if value_str.startswith("<") and value_str.endswith(">"):
            counters[event_name] = None
            continue
        normalized = value_str.replace(",", "").strip()
        try:
            counters[event_name] = float(normalized)
        except ValueError:
            continue
    return counters


def _get_perf_counter_value(counters: Dict[str, Optional[float]], event_name: str) -> Optional[float]:
    """å…¼å®¹ perf è¾“å‡º event åå¸¦ :u/:k ç­‰ä¿®é¥°ç¬¦çš„æƒ…å†µã€‚"""
    if event_name in counters:
        return counters[event_name]
    for key, value in counters.items():
        base = key.split(":", 1)[0]
        if base == event_name:
            return value
    return None


def _perf_output_indicates_unsupported(stderr_text: str) -> bool:
    lowered = stderr_text.lower()
    return (
        "not supported" in lowered
        or "unknown event" in lowered
        or "failed to find event" in lowered
        or "no such file or directory" in lowered
    )


def _perf_output_indicates_permission_issue(stderr_text: str) -> bool:
    lowered = stderr_text.lower()
    return ("permission" in lowered and "denied" in lowered) or "no permission" in lowered


def _perf_sample_l3_hit_rate_for_pid(
    pid: int,
    sample_seconds: float,
    loads_event: str,
    misses_event: str,
) -> Dict[str, Any]:
    cmd = [
        "perf",
        "stat",
        "-x",
        ",",
        "-e",
        f"{loads_event},{misses_event}",
        "-p",
        str(pid),
        "--",
        "sleep",
        str(sample_seconds),
    ]
    raw = execute_shell_command(cmd, timeout=max(6, int(sample_seconds) + 5))
    perf_text = f"{raw.get('stderr', '')}\n{raw.get('stdout', '')}"
    counters = _parse_perf_stat_csv(perf_text)
    loads = _get_perf_counter_value(counters, loads_event)
    misses = _get_perf_counter_value(counters, misses_event)
    hit_rate: Optional[float] = None
    if loads is not None and misses is not None and loads > 0:
        hit_rate = max(0.0, min(1.0, (loads - misses) / loads))
    return {
        "exit_code": raw.get("exit_code", -2),
        "loads_event": loads_event,
        "misses_event": misses_event,
        "loads": loads,
        "misses": misses,
        "hit_rate": hit_rate,
        "stderr": raw.get("stderr", ""),
        "stdout": raw.get("stdout", ""),
    }


def _perf_sample_l3_hit_rate_for_pid_with_retry(
    pid: int,
    sample_seconds: float,
    loads_event: str,
    misses_event: str,
    max_attempts: int = 3,
) -> Dict[str, Any]:
    """
    perf stat å¶å‘ä¼šè¾“å‡º <not counted> å¯¼è‡´ loads/misses è§£æä¸º Noneã€‚
    è¿™é‡Œé€šè¿‡å»¶é•¿é‡‡æ ·çª—å£é‡è¯•ï¼Œå°½é‡ä¿è¯è¿”å›å¯ç”¨äºè®¡ç®— hit_rate çš„è®¡æ•°ç»“æœã€‚
    """
    last: Optional[Dict[str, Any]] = None
    for attempt in range(1, max_attempts + 1):
        duration = sample_seconds * (2 ** (attempt - 1))
        sample = _perf_sample_l3_hit_rate_for_pid(pid, duration, loads_event, misses_event)
        sample["attempt"] = attempt
        sample["sample_seconds"] = duration
        last = sample

        loads = sample.get("loads")
        misses = sample.get("misses")
        if loads is not None and misses is not None and loads > 0:
            return sample

        stderr_text = str(sample.get("stderr", "") or "")
        if _perf_output_indicates_permission_issue(stderr_text) or _perf_output_indicates_unsupported(stderr_text):
            break

    return last or {
        "exit_code": -2,
        "loads_event": loads_event,
        "misses_event": misses_event,
        "loads": None,
        "misses": None,
        "hit_rate": None,
        "stderr": "perf é‡‡æ ·å¤±è´¥ï¼šæ— å¯ç”¨ç»“æœ",
        "stdout": "",
        "attempt": 0,
        "sample_seconds": sample_seconds,
    }


def sample_workload_l3_hit_rate(
    pids: List[int],
    sample_seconds: float = 0.5,
    max_workers: int = 6,
) -> Dict[str, Any]:
    """å¯¹æ¯ä¸ª PID ä½¿ç”¨ perf é‡‡æ · L3 å‘½ä¸­ç‡ï¼ˆhit_rate = 1 - misses / loadsï¼‰ã€‚"""
    if not pids:
        return {
            "exit_code": 0,
            "results": {},
            "loads_event": "LLC-loads",
            "misses_event": "LLC-load-misses",
            "stderr": "",
        }

    event_candidates = [
        ("LLC-loads", "LLC-load-misses"),
        ("cache-references", "cache-misses"),
    ]
    loads_event, misses_event = event_candidates[0]

    # å…ˆç”¨é¦–ä¸ªPIDæ¢æµ‹ä¸€æ¬¡äº‹ä»¶æ˜¯å¦å¯ç”¨ï¼›ä»…å½“æ˜ç¡®â€œä¸æ”¯æŒâ€æ—¶å›é€€åˆ°æ›´é€šç”¨çš„ cache-* äº‹ä»¶
    probe = _perf_sample_l3_hit_rate_for_pid(pids[0], min(sample_seconds, 0.2), loads_event, misses_event)
    if _perf_output_indicates_unsupported(str(probe.get("stderr", "") or "")):
        loads_event, misses_event = event_candidates[1]

    results: Dict[str, Any] = {}
    errors: List[str] = []
    worker_count = max(1, min(max_workers, len(pids)))
    with ThreadPoolExecutor(max_workers=worker_count) as executor:
        future_map = {
            executor.submit(_perf_sample_l3_hit_rate_for_pid_with_retry, pid, sample_seconds, loads_event, misses_event): pid
            for pid in pids
        }
        for future in as_completed(future_map):
            pid = future_map[future]
            try:
                results[str(pid)] = future.result()
            except Exception as exc:
                errors.append(f"PID {pid}: perf é‡‡æ ·å¤±è´¥ï¼š{exc}")
                results[str(pid)] = {
                    "exit_code": -2,
                    "loads_event": loads_event,
                    "misses_event": misses_event,
                    "loads": None,
                    "misses": None,
                    "hit_rate": None,
                    "stderr": str(exc),
                }

    return {
        "exit_code": 0 if not errors else -1,
        "loads_event": loads_event,
        "misses_event": misses_event,
        "results": results,
        "stderr": "\n".join(errors),
    }


def _parse_top_cpu_percent(output_text: str) -> Dict[int, float]:
    cpu_index: Optional[int] = None
    cpu_by_pid: Dict[int, float] = {}

    for line in output_text.splitlines():
        stripped = line.lstrip()
        if not stripped:
            continue

        if stripped.startswith("PID "):
            cols = stripped.split()
            if "%CPU" in cols:
                cpu_index = cols.index("%CPU")
            continue

        if not stripped[0].isdigit():
            continue

        parts = stripped.split()
        if not parts or not parts[0].isdigit():
            continue
        pid = int(parts[0])
        idx = cpu_index if cpu_index is not None else 8
        if len(parts) <= idx:
            continue
        try:
            cpu_by_pid[pid] = float(parts[idx].replace("%", ""))
        except ValueError:
            continue

    return cpu_by_pid


def sample_workload_cpu_percent_top(
    pids: List[int],
    delay_seconds: float = 0.2,
    iterations: int = 2,
    chunk_size: int = 20,
) -> Dict[str, Any]:
    """ä½¿ç”¨ top æ‰¹é‡é‡‡æ ·æ¯ä¸ª PID çš„ CPU åˆ©ç”¨ç‡ï¼ˆ%CPUï¼‰ã€‚"""
    if not pids:
        return {"exit_code": 0, "cpu_percent": {}, "stderr": "", "stdout": ""}

    cpu_percent: Dict[str, Optional[float]] = {str(pid): None for pid in pids}
    errors: List[str] = []
    raw_outputs: List[str] = []

    for i in range(0, len(pids), chunk_size):
        chunk = pids[i : i + chunk_size]
        cmd = [
            "top",
            "-b",
            "-n",
            str(iterations),
            "-d",
            str(delay_seconds),
            "-p",
            ",".join(str(pid) for pid in chunk),
        ]
        raw = execute_shell_command(cmd, timeout=max(5, int(delay_seconds * iterations) + 3))
        if raw.get("stdout"):
            raw_outputs.append(raw["stdout"])
        if raw.get("exit_code") != 0:
            errors.append(raw.get("stderr", "") or f"top é‡‡æ ·å¤±è´¥ï¼šexit_code={raw.get('exit_code')}")
            continue
        parsed = _parse_top_cpu_percent(raw.get("stdout", ""))
        for pid, value in parsed.items():
            cpu_percent[str(pid)] = value

    return {
        "exit_code": 0 if not errors else -1,
        "cpu_percent": cpu_percent,
        "stderr": "\n".join(e for e in errors if e),
        "stdout": "\n\n".join(raw_outputs[-1:]),
    }


def collect_latest_benchmark_samples(pids: Optional[List[int]] = None) -> Dict[str, Any]:
    """ä»ä¸´æ—¶æ–‡ä»¶è¯»å–æ¯ä¸ªè¿›ç¨‹æœ€è¿‘ä¸€æ¬¡benchmarké‡‡æ ·æ—¥å¿—"""
    if pids is None:
        pids = get_tracked_pids()
    lines: List[str] = []
    errors: List[str] = []
    for pid in pids:
        path = _sample_file_for_pid(pid)
        try:
            text = path.read_text(encoding="utf-8", errors="ignore").strip()
            if text:
                lines.append(f"PID {pid}: {text}")
        except FileNotFoundError:
            continue
        except Exception as exc:
            errors.append(f"PID {pid} è¯»å–å¤±è´¥: {exc}")
    return {
        "exit_code": 0 if not errors else -1,
        "stdout": "\n".join(lines),
        "stderr": "\n".join(errors),
    }

OPS_PER_SECOND_PATTERN = re.compile(
    r"PID\s+(?P<pid>\d+):.*?Ops per second:\s*(?P<ops>[0-9]+(?:\.[0-9]+)?)",
    re.IGNORECASE,
)


def parse_ops_per_second_from_benchmark_latest(latest_log: Dict[str, Any]) -> Dict[int, float]:
    """è§£æ collect_latest_benchmark_samples çš„ stdoutï¼Œæå–æ¯ä¸ª PID çš„ Ops per secondã€‚"""
    stdout = str(latest_log.get("stdout", "") or "")
    ops_by_pid: Dict[int, float] = {}
    for line in stdout.splitlines():
        m = OPS_PER_SECOND_PATTERN.search(line)
        if not m:
            continue
        try:
            pid = int(m.group("pid"))
            ops = float(m.group("ops"))
        except Exception:
            continue
        ops_by_pid[pid] = ops
    return ops_by_pid


def compute_ops_change_rate_reward(
    before_latest: Dict[str, Any],
    after_latest: Dict[str, Any],
) -> Dict[str, Any]:
    """
    reward è®¡ç®—ï¼š
    - å¯¹æ¯ä¸ª PIDï¼šchange_rate = (after_ops - before_ops) / before_ops
    - reward_scoreï¼šæ‰€æœ‰æœ‰æ•ˆ PID çš„ change_rate å‡å€¼
    """
    before_ops = parse_ops_per_second_from_benchmark_latest(before_latest)
    after_ops = parse_ops_per_second_from_benchmark_latest(after_latest)

    per_pid_change_rate: Dict[str, Optional[float]] = {}
    valid_rates: List[float] = []
    stdout_lines: List[str] = []
    for pid, after in after_ops.items():
        before = before_ops.get(pid)
        if before is None or before <= 0:
            per_pid_change_rate[str(pid)] = None
            stdout_lines.append(f"PID {pid}: before_ops=N/A after_ops={after} change_rate=N/A")
            continue
        rate = (after - before) / before
        per_pid_change_rate[str(pid)] = rate
        valid_rates.append(rate)
        stdout_lines.append(f"PID {pid}: before_ops={before} after_ops={after} change_rate={rate}")

    score = sum(valid_rates) / len(valid_rates) if valid_rates else 0.0
    stderr_parts: List[str] = []
    if not valid_rates:
        stderr_parts.append("æœªæ‰¾åˆ°å¯ç”¨äºè®¡ç®— reward çš„æœ‰æ•ˆ PIDï¼ˆç¼ºå°‘ before/after æˆ– before_ops<=0ï¼‰")

    return {
        "exit_code": 0 if valid_rates else -1,
        "score": score,
        "stdout": "\n".join(stdout_lines + [f"mean_change_rate: {score}"]),
        "per_pid_change_rate": per_pid_change_rate,
        "before_ops_per_second": {str(pid): val for pid, val in before_ops.items()},
        "after_ops_per_second": {str(pid): val for pid, val in after_ops.items()},
        "stderr": "\n".join(stderr_parts),
    }


def failure_reward(reason: str) -> Dict[str, Any]:
    return {
        "exit_code": -1,
        "score": -1.0,
        "stdout": "",
        "per_pid_change_rate": {},
        "before_ops_per_second": {},
        "after_ops_per_second": {},
        "stderr": reason,
    }


def collect_baseline_sample() -> Dict[str, Any]:
    """é‡‡é›†å½“å‰æœºå™¨çš„åˆå§‹ ps/lscpu + workload(pid) ç»´åº¦çš„ perf/top é‡‡æ ·"""
    workload_processes = get_workload_processes()
    workload_pids = [item["pid"] for item in workload_processes]
    samples = {
        "ps_ef": execute_shell_command(["ps", "-ef"], timeout=5),
        "lscpu": execute_shell_command(["lscpu"], timeout=5),
        "workload_processes": workload_processes,
        "workload_l3_hit_rate": sample_workload_l3_hit_rate(workload_pids, sample_seconds=0.5),
        "workload_cpu_percent": sample_workload_cpu_percent_top(workload_pids, delay_seconds=0.2, iterations=2),
    }
    samples["benchmark_latest"] = collect_latest_benchmark_samples(workload_pids)
    return samples

def _is_intensive_command(tokens: List[str]) -> bool:
    """åˆ¤æ–­å‘½ä»¤è¡Œä¸­æ˜¯å¦åŒ…å« *intensive çš„äºŒè¿›åˆ¶"""
    for token in tokens:
        name = Path(token).name
        if name.endswith("intensive"):
            return True
    return False


def _pid_is_intensive(pid: int) -> bool:
    """æ£€æŸ¥ç»™å®šPIDæ˜¯å¦å¯¹åº” *intensive ç»“å°¾çš„ä»»åŠ¡"""
    try:
        cmdline = Path(f"/proc/{pid}/cmdline").read_bytes().split(b"\0")
        for part in cmdline:
            if not part:
                continue
            if Path(part.decode(errors="ignore")).name.endswith("intensive"):
                return True
    except Exception:
        pass
    try:
        ps = subprocess.run(
            ["ps", "-p", str(pid), "-o", "comm="],
            stdout=subprocess.PIPE,
            stderr=subprocess.PIPE,
            text=True,
            timeout=3
        )
        for line in ps.stdout.splitlines():
            if Path(line.strip()).name.endswith("intensive"):
                return True
    except Exception:
        pass
    return False


def _format_command(command_args: Any) -> str:
    """å°†Popençš„argsè½¬æ¢ä¸ºæ˜“è¯»çš„å­—ç¬¦ä¸²å½¢å¼"""
    if isinstance(command_args, (list, tuple)):
        return shlex.join([str(arg) for arg in command_args])
    return str(command_args)


def unregister_tracked_process(pid: int) -> None:
    """ä»å…¨å±€è·Ÿè¸ªè¡¨ä¸­ç§»é™¤æŒ‡å®šPID"""
    with process_registry_lock:
        tracked_processes.pop(pid, None)


def register_tracked_process(proc: subprocess.Popen, source: str) -> None:
    """è®°å½•ç”±serverå¯åŠ¨çš„è¿›ç¨‹ï¼Œå¹¶åœ¨é€€å‡ºåè‡ªåŠ¨æ¸…ç†"""
    cmd_str = _format_command(proc.args)
    with process_registry_lock:
        tracked_processes[proc.pid] = TrackedProcess(
            proc=proc,
            command=cmd_str,
            source=source,
            start_time=time.time()
        )

    def _auto_cleanup() -> None:
        try:
            proc.wait()
        except Exception:
            # é€€å‡ºå¼‚å¸¸ä¸å½±å“æ¸…ç†
            pass
        unregister_tracked_process(proc.pid)

    threading.Thread(target=_auto_cleanup, daemon=True).start()


def cleanup_finished_processes() -> None:
    """ç§»é™¤å·²é€€å‡ºçš„è¿›ç¨‹ï¼Œé˜²æ­¢è·Ÿè¸ªè¡¨æ³„æ¼"""
    with process_registry_lock:
        finished = [pid for pid, tracked in tracked_processes.items() if tracked.proc.poll() is not None]
        for pid in finished:
            tracked_processes.pop(pid, None)


def stop_all_tracked_processes(timeout: float = 5.0) -> Dict[str, Any]:
    """
    ç»ˆæ­¢å½“å‰ç”±serverå¯åŠ¨å¹¶ä»åœ¨è¿è¡Œçš„æ‰€æœ‰è¿›ç¨‹ã€‚
    :return: æ±‡æ€»ä¿¡æ¯ï¼ˆåœæ­¢æ•°é‡/å·²é€€å‡º/é”™è¯¯/è¯¦ç»†åˆ—è¡¨ï¼‰
    """
    cleanup_finished_processes()
    with process_registry_lock:
        tracked_items = list(tracked_processes.items())

    results: List[Dict[str, Any]] = []
    for pid, tracked in tracked_items:
        proc = tracked.proc
        status: Dict[str, Any] = {
            "pid": pid,
            "command": tracked.command,
            "source": tracked.source
        }
        try:
            if proc.poll() is None:
                proc.terminate()
                try:
                    proc.wait(timeout=timeout)
                    status["status"] = "terminated"
                except subprocess.TimeoutExpired:
                    proc.kill()
                    status["status"] = "killed"
                status["exit_code"] = proc.returncode
            else:
                status["status"] = "already_exited"
                status["exit_code"] = proc.returncode
        except Exception as e:
            status["status"] = "error"
            status["error"] = str(e)
        finally:
            unregister_tracked_process(pid)
        results.append(status)

    summary = {
        "total_processed": len(results),
        "stopped": len([r for r in results if r["status"] in ("terminated", "killed")]),
        "already_exited": len([r for r in results if r["status"] == "already_exited"]),
        "errors": len([r for r in results if r["status"] == "error"]),
        "details": results
    }
    with process_registry_lock:
        summary["remaining_after_stop"] = len(tracked_processes)
    return summary


def random_generate_load_counts() -> Dict[str, int]:
    load_counts: Dict[str, int] = {}
    for load_name, (min_cnt, max_cnt) in LOAD_COUNT_RANGE.items():
        load_counts[load_name] = random.randint(min_cnt, max_cnt)
    total = sum(load_counts.values())
    if total == 0:
        print("âš ï¸ æ‰€æœ‰è´Ÿè½½éšæœºæ•°é‡å‡ä¸º0ï¼Œå¼ºåˆ¶ä¸ºcomputeç±»å‹åˆ†é…1ä¸ªå®ä¾‹")
        load_counts["compute"] = 1
    return load_counts

def check_benchmark_dependencies() -> bool:
    """æ£€æŸ¥benchmarkå¯æ‰§è¡Œæ–‡ä»¶æ˜¯å¦å­˜åœ¨ä¸”å¯æ‰§è¡Œ"""
    required = [
        BENCHMARK_BIN_DIR / "compute_intensive",
        BENCHMARK_BIN_DIR / "mem_intensive",
        BENCHMARK_BIN_DIR / "cache_sensitive",
        BENCHMARK_BIN_DIR / "io_disk_intensive"
    ]
    missing = [str(p) for p in required if not p.exists() or not os.access(p, os.X_OK)]
    if missing:
        print(f"é”™è¯¯ï¼šç¼ºå°‘å¯æ‰§è¡Œæ–‡ä»¶æˆ–æƒé™ä¸è¶³ï¼š{', '.join(missing)}")
        return False
    return True


def build_load_command(load_name: str) -> List[str]:
    if load_name == "compute":
        return [
            str(BENCHMARK_BIN_DIR / "compute_intensive"),
            "-t", str(COMPUTE_THREADS),
            "-T", str(COMPUTE_THREADS),
            "-f", "0",
            "-d", "0",
            "-r", str(TEST_DURATION)
        ]
    if load_name == "mem":
        return [
            str(BENCHMARK_BIN_DIR / "mem_intensive"),
            "-t", str(MEM_THREADS),
            "-T", str(MEM_THREADS),
            "-M", str(MEM_SIZE_MB),
            "-g", str(MEM_GRANULARITY),
            "-s", str(MEM_SEQUENTIAL),
            "-f", "0",
            "-d", "0",
            "-r", str(TEST_DURATION)
        ]
    if load_name == "cache":
        return [
            str(BENCHMARK_BIN_DIR / "cache_sensitive"),
            "-t", str(CACHE_THREADS),
            "-T", str(CACHE_THREADS),
            "-C", str(CACHE_SIZE_MB),
            "-f", "0",
            "-d", "0",
            "-r", str(TEST_DURATION)
        ]
    if load_name == "disk":
        return [
            str(BENCHMARK_BIN_DIR / "io_disk_intensive"),
            "-t", str(DISK_THREADS),
            "-T", str(DISK_THREADS),
            "-p", str(DISK_TEST_FILE),
            "-F", str(DISK_FILE_SIZE_MB),
            "-b", str(DISK_BLOCK_SIZE_KB),
            "-s", str(DISK_SEQUENTIAL),
            "-R", str(DISK_READ_ONLY),
            "-f", "0",
            "-d", "0",
            "-r", str(TEST_DURATION)
        ]
    raise ValueError(f"æœªçŸ¥è´Ÿè½½ç±»å‹ï¼š{load_name}")


def start_load_instances(load_counts: Dict[str, int]) -> List[tuple]:
    processes = []
    total_instances = sum(load_counts.values())
    print(f"\nğŸš€ å¼€å§‹å¯åŠ¨ {total_instances} ä¸ªbenchmarkä»»åŠ¡è¿›ç¨‹ï¼ˆæŒ‰ç±»å‹éšæœºåˆ†é…ï¼‰ï¼š")
    for load_name, count in load_counts.items():
        if count <= 0:
            print(f"  - {load_name}: 0 ä¸ªå®ä¾‹ï¼ˆè·³è¿‡ï¼‰")
            continue
        print(f"  - {load_name}: {count} ä¸ªå®ä¾‹")
        for idx in range(1, count + 1):
            try:
                cmd = build_load_command(load_name)
                proc = subprocess.Popen(
                    cmd,
                    stdout=subprocess.DEVNULL,
                    stderr=subprocess.DEVNULL,
                    close_fds=True,
                    cwd=str(BENCHMARK_DIR)
                )
                register_tracked_process(proc, source=f"benchmark:{load_name}[{idx}]")
                processes.append((load_name, idx, proc))
                print(f"    âœ… å·²å¯åŠ¨ {load_name}[{idx}] (PID: {proc.pid})")
            except Exception as e:
                print(f"    âŒ å¯åŠ¨ {load_name}[{idx}] å¤±è´¥ï¼š{str(e)}")
    return processes


def wait_for_processes(processes: List[tuple]) -> None:
    if not processes:
        return
    print(f"\nâŒ› ç­‰å¾…æ‰€æœ‰benchmarkå®ä¾‹è¿è¡Œ {TEST_DURATION} ç§’...")
    start_time = time.time()
    for load_name, idx, proc in processes:
        try:
            proc.wait(timeout=TEST_DURATION + 5)
            exit_code = proc.returncode
            if exit_code == 0:
                print(f"âœ… {load_name}[{idx}] è¿è¡Œå®Œæˆ (é€€å‡ºç : {exit_code})")
            else:
                print(f"âš ï¸ {load_name}[{idx}] å¼‚å¸¸é€€å‡º (é€€å‡ºç : {exit_code})")
        except subprocess.TimeoutExpired:
            print(f"âš ï¸ {load_name}[{idx}] è¿è¡Œè¶…æ—¶ï¼Œå¼ºåˆ¶ç»ˆæ­¢")
            proc.kill()
        finally:
            unregister_tracked_process(proc.pid)
    if DISK_TEST_FILE.exists():
        try:
            os.remove(DISK_TEST_FILE)
            print(f"\nğŸ—‘ï¸ å·²æ¸…ç†ç£ç›˜æµ‹è¯•æ–‡ä»¶ï¼š{DISK_TEST_FILE}")
        except Exception as e:
            print(f"âš ï¸ æ¸…ç†ç£ç›˜æµ‹è¯•æ–‡ä»¶å¤±è´¥ï¼š{str(e)}")
    elapsed = time.time() - start_time
    print(f"\nğŸ“Š æ‰€æœ‰benchmarkå®ä¾‹è¿è¡Œå®Œæˆï¼Œæ€»è€—æ—¶ï¼š{elapsed:.2f} ç§’")


def launch_random_workload() -> tuple[List[tuple], Dict[str, int]]:
    """ç”Ÿæˆéšæœºè´Ÿè½½å¹¶å¯åŠ¨è¿›ç¨‹ï¼Œè¿”å›è¿›ç¨‹åˆ—è¡¨å’Œæ•°é‡é…ç½®"""
    if not check_benchmark_dependencies():
        return [], {}
    load_counts = random_generate_load_counts()
    print("\nğŸ“‹ éšæœºç”Ÿæˆçš„benchmarkå®ä¾‹æ•°é‡ï¼š")
    for load_name, count in load_counts.items():
        print(f"  - {load_name}: {count} ä¸ª")
    processes = start_load_instances(load_counts)
    return processes, load_counts


def start_benchmark_workload() -> None:
    """æœåŠ¡å¯åŠ¨æ—¶ç›´æ¥åœ¨å½“å‰è¿›ç¨‹å¯åŠ¨éšæœºbenchmarkè´Ÿè½½"""
    try:
        processes, _ = launch_random_workload()
        if not processes:
            return
        wait_for_processes(processes)
        print("\nğŸ‰ éšæœºå¤šè¿›ç¨‹benchmarkè´Ÿè½½å®Œæˆï¼")
    except Exception as e:
        print(f"âŒ benchmark ä»»åŠ¡å¼‚å¸¸ï¼š{str(e)}")


def trigger_random_workload_async(source: str = "manual") -> List[int]:
    """ä»¥åå°çº¿ç¨‹æ–¹å¼å¯åŠ¨ä¸€æ¬¡éšæœºbenchmarkè´Ÿè½½ï¼Œè¿”å›æ–°è¿›ç¨‹çš„PIDåˆ—è¡¨"""
    try:
        processes, _ = launch_random_workload()
        if not processes:
            return []
        threading.Thread(
            target=wait_for_processes,
            args=(processes,),
            daemon=True,
            name=f"random-workload-{source}"
        ).start()
        return [proc.pid for _, _, proc in processes]
    except Exception as e:
        print(f"âŒ è§¦å‘éšæœºè´Ÿè½½å¤±è´¥ï¼š{str(e)}")
        return []


def sample_process_state(pid: int) -> Dict[str, Any]:
    """é‡‡é›† ps/lscpu + workload(pid) ç»´åº¦çš„ perf/top é‡‡æ ·"""
    samples: Dict[str, Any] = {}

    # ä¸åŸºçº¿é‡‡æ ·ä¿æŒä¸€è‡´ï¼šå…¨é‡ps/lscpu + per-pid perf/top
    samples["ps_ef"] = execute_shell_command(["ps", "-ef"], timeout=5)
    samples["lscpu"] = execute_shell_command(["lscpu"], timeout=5)
    workload_processes = get_workload_processes()
    workload_pids = [item["pid"] for item in workload_processes]
    samples["workload_processes"] = workload_processes
    samples["workload_l3_hit_rate"] = sample_workload_l3_hit_rate(workload_pids, sample_seconds=0.5)
    samples["workload_cpu_percent"] = sample_workload_cpu_percent_top(workload_pids, delay_seconds=0.2, iterations=2)
    # è¿”å›æ‰€æœ‰è´Ÿè½½è¿›ç¨‹çš„æœ€æ–°é‡‡æ ·æ—¥å¿—ï¼Œè€Œéä»…ç›®æ ‡PID
    samples["benchmark_latest"] = collect_latest_benchmark_samples(workload_pids)
    return samples


def run_single_bind_command(command_str: str) -> BindCommandResult:
    """æ‰§è¡Œå•æ¡ç»‘æ ¸æŒ‡ä»¤ï¼Œç­‰å¾…1ç§’åé‡‡æ ·ï¼Œå†è§£é™¤ç»‘æ ¸"""
    result = BindCommandResult(
        command=command_str,
        pid=None,
        bind_success=False,
        sample_results={},
        exit_code=-1,
        reward=None,
        error_msg=""
    )
    proc: Optional[subprocess.Popen] = None
    try:
        cmd_parts = shlex.split(command_str)
        if not cmd_parts:
            result.error_msg = "å‘½ä»¤ä¸èƒ½ä¸ºç©º"
            result.reward = failure_reward(result.error_msg)
            return result

        base_cmd = cmd_parts[0]
        if base_cmd not in ALLOWED_BASE_COMMANDS:
            result.error_msg = f"ç¦æ­¢æ‰§è¡Œå‘½ä»¤ï¼š{base_cmd}ï¼ˆä»…å…è®¸{ALLOWED_BASE_COMMANDS}ï¼‰"
            result.reward = failure_reward(result.error_msg)
            return result

        # ç»‘å®šå¯¹è±¡å¿…é¡»æ˜¯ *intensive ä»»åŠ¡
        if base_cmd == "numactl" and not _is_intensive_command(cmd_parts):
            result.error_msg = "numactl ç»‘å®šçš„ç›®æ ‡å‘½ä»¤å¿…é¡»æ˜¯ *intensive äºŒè¿›åˆ¶"
            result.reward = failure_reward(result.error_msg)
            return result

        sample_pid: Optional[int] = None
        if base_cmd == "taskset":
            for token in reversed(cmd_parts):
                if token.isdigit():
                    sample_pid = int(token)
                    break
            if sample_pid is None:
                result.error_msg = "tasksetç»‘æ ¸ç¼ºå°‘ç›®æ ‡PID"
                result.reward = failure_reward(result.error_msg)
                return result
            if not _pid_is_intensive(sample_pid):
                result.error_msg = f"PID {sample_pid} ä¸æ˜¯ *intensive ç»“å°¾çš„ä»»åŠ¡ï¼Œæ‹’ç»ç»‘æ ¸"
                result.reward = failure_reward(result.error_msg)
                return result

        # reward baselineï¼šå…ˆé‡‡ä¸€ä»½â€œæ‰§è¡Œå‰â€çš„æœ€æ–° benchmark æ—¥å¿—
        workload_processes = get_workload_processes()
        workload_pids = [item["pid"] for item in workload_processes]
        before_latest = collect_latest_benchmark_samples(workload_pids)

        proc = subprocess.Popen(
            cmd_parts,
            stdout=subprocess.PIPE,
            stderr=subprocess.PIPE,
            encoding="utf-8",
            errors="ignore"
        )
        register_tracked_process(proc, source=f"bind_task:{base_cmd}")
        result.bind_success = True
        result.pid = sample_pid if sample_pid is not None else proc.pid

        # taskset å±äºçŸ­å‘½ä»¤ï¼šç­‰å¾…å…¶ç»“æŸå¹¶æ£€æŸ¥é€€å‡ºç ï¼Œå¤±è´¥åˆ™ç›´æ¥è¿”å› reward=-1.0
        if base_cmd == "taskset":
            stdout_text, stderr_text = proc.communicate(timeout=5)
            result.exit_code = proc.returncode if proc.returncode is not None else -1
            if result.exit_code != 0:
                result.bind_success = False
                result.error_msg = (stderr_text or stdout_text or f"taskset æ‰§è¡Œå¤±è´¥ï¼šexit_code={result.exit_code}").strip()
                result.reward = failure_reward(result.error_msg)
                return result

        # è¿è¡Œ1ç§’åé‡‡æ ·
        time.sleep(1)
        result.sample_results = sample_process_state(result.pid or 0)

        # å¯¹äºé taskset å‘½ä»¤ï¼šè‹¥å·²é€€å‡ºä¸”è¿”å›ç é0ï¼Œè§†ä¸ºæ‰§è¡Œå¤±è´¥
        proc.poll()
        if proc.returncode is not None:
            result.exit_code = proc.returncode
            if proc.returncode != 0:
                stdout_text, stderr_text = proc.communicate(timeout=2)
                result.bind_success = False
                result.error_msg = (stderr_text or stdout_text or f"{base_cmd} æ‰§è¡Œå¤±è´¥ï¼šexit_code={proc.returncode}").strip()
                result.reward = failure_reward(result.error_msg)
                return result

        after_latest = {}
        if isinstance(result.sample_results, dict):
            after_latest = result.sample_results.get("benchmark_latest", {}) or {}
        if isinstance(after_latest, dict):
            result.reward = compute_ops_change_rate_reward(before_latest, after_latest)
        else:
            result.reward = failure_reward("benchmark_latest ç¼ºå¤±ï¼Œæ— æ³•è®¡ç®— reward")

        if proc and proc.returncode is None:
            result.exit_code = 0
    except Exception as e:
        result.error_msg = f"å‘½ä»¤æ‰§è¡Œå¼‚å¸¸ï¼š{str(e)}\n{traceback.format_exc()}"
        if result.reward is None:
            result.reward = failure_reward(result.error_msg)
        if proc and proc.poll() is None:
            proc.kill()
    finally:
        cleanup_finished_processes()
    return result


def process_bind_task(task_params: Dict[str, Any]) -> BindTaskResult:
    """å¤„ç†ä¸€ä¸²ç»‘æ ¸æŒ‡ä»¤ï¼šæŒ‰é¡ºåºæ‰§è¡Œå¹¶é‡‡æ ·ï¼Œè¿”å›èšåˆç»“æœ"""
    request_id = task_params["request_id"]
    commands: List[str] = task_params["bind_commands"]

    command_results: List[BindCommandResult] = []
    success = True
    error_msg = ""

    try:
        for cmd in commands:
            single_result = run_single_bind_command(cmd)
            if not single_result.bind_success and single_result.reward is None:
                single_result.reward = failure_reward(single_result.error_msg or "å‘½ä»¤æ‰§è¡Œå¤±è´¥")
            command_results.append(single_result)
            if not single_result.bind_success:
                success = False
                if not error_msg:
                    error_msg = single_result.error_msg
    except Exception as e:
        success = False
        error_msg = f"ä»»åŠ¡æ‰§è¡Œå¼‚å¸¸ï¼š{str(e)}\n{traceback.format_exc()}"

    task_reward = command_results[-1].reward if command_results else None
    if not success:
        task_reward = failure_reward(error_msg or "ä»»åŠ¡æ‰§è¡Œå¤±è´¥")
    return BindTaskResult(
        request_id=request_id,
        success=success,
        command_results=command_results,
        reward=task_reward,
        error_msg=error_msg
    )

def process_queue():
    """å¤„ç†ä»»åŠ¡é˜Ÿåˆ—ï¼ˆåå°çº¿ç¨‹ï¼Œä¸²è¡Œæ‰§è¡Œï¼‰"""
    global is_processing
    with queue_lock:
        if is_processing or not task_queue:
            return
        is_processing = True

    try:
        while True:
            with queue_lock:
                if not task_queue:
                    break
                current_task = task_queue.pop(0)  # FIFO
                processing_requests.add(current_task["request_id"])

            try:
                result = process_bind_task(current_task)
            finally:
                with queue_lock:
                    processing_requests.discard(current_task["request_id"])

            # å­˜å‚¨ç»“æœï¼ˆä¾›è°ƒç”¨æ–¹è·å–ï¼Œè¿™é‡Œç®€åŒ–ä¸ºå†…å­˜å­˜å‚¨ï¼Œç”Ÿäº§ç¯å¢ƒå¯æ”¹ç”¨Redis/æ•°æ®åº“ï¼‰
            with queue_lock:
                completed_results[result.request_id] = result

    finally:
        with queue_lock:
            is_processing = False


@app.on_event("startup")
async def on_startup():
    """æœåŠ¡å¯åŠ¨æ—¶ç›´æ¥è§¦å‘benchmarkè´Ÿè½½"""
    trigger_random_workload_async(source="startup")

# ======================== APIæ¥å£ ========================
@app.post("/bind-tasks")
async def submit_bind_tasks(
    request_id: str = Body(..., description="å”¯ä¸€è¯·æ±‚ID"),
    bind_commands: List[str] = Body(..., description="ä¸€ä¸²ç»‘æ ¸æŒ‡ä»¤ï¼ˆæŒ‰é¡ºåºæ‰§è¡Œï¼‰"),
    x_api_key: str = Header(None, description="APIé‰´æƒKey")
):
    """æäº¤ç»‘æ ¸æŒ‡ä»¤åºåˆ—ï¼Œæ”¾å…¥é˜Ÿåˆ—æŒ‰é¡ºåºæ‰§è¡Œï¼ˆå¼‚æ­¥ï¼Œç«‹å³è¿”å›ï¼‰"""
    if x_api_key != AUTH_API_KEY:
        raise HTTPException(status_code=401, detail="æœªæˆæƒï¼šAPI Keyé”™è¯¯")

    if not bind_commands:
        print("bind_commandsä¸èƒ½ä¸ºç©º")
        raise HTTPException(status_code=400, detail="bind_commandsä¸èƒ½ä¸ºç©º")

    with queue_lock:
        duplicate = (
            any(task["request_id"] == request_id for task in task_queue)
            or request_id in completed_results
            or request_id in processing_requests
        )
        if duplicate:
            print(f"è¯·æ±‚ID{request_id}å·²å­˜åœ¨ï¼Œè¯·å‹¿é‡å¤æäº¤")
            raise HTTPException(status_code=400, detail=f"è¯·æ±‚ID{request_id}å·²å­˜åœ¨ï¼Œè¯·å‹¿é‡å¤æäº¤")

        task_queue.append({"request_id": request_id, "bind_commands": bind_commands})
        queued_size = len(task_queue)

    threading.Thread(target=process_queue, daemon=True).start()

    return JSONResponse(
        status_code=200,
        content={
            "code": 200,
            "msg": "ä»»åŠ¡å·²å…¥é˜Ÿï¼Œç­‰å¾…æ‰§è¡Œ",
            "data": {
                "request_id": request_id,
                "queue_size": queued_size
            }
        }
    )


@app.get("/bind-tasks/{request_id}")
async def query_bind_result(
    request_id: str,
    x_api_key: str = Header(None, description="APIé‰´æƒKey")
):
    """æ ¹æ®request_idæŸ¥è¯¢ç»‘æ ¸é‡‡æ ·ç»“æœï¼ˆè¿è¡Œä¸­/æœªæ‰¾åˆ°/å·²å®Œæˆï¼‰"""
    if x_api_key != AUTH_API_KEY:
        raise HTTPException(status_code=401, detail="æœªæˆæƒï¼šAPI Keyé”™è¯¯")

    with queue_lock:
        if request_id in completed_results:
            result = completed_results[request_id]
            result_dict = asdict(result)
            reward_detail = result_dict.get("reward")
            reward_score: float
            if isinstance(reward_detail, dict) and isinstance(reward_detail.get("score"), (int, float)):
                reward_score = float(reward_detail["score"])
            else:
                reward_score = -1.0
            if not result.success:
                reward_score = -1.0
            return JSONResponse(
                status_code=200,
                content={
                    "code": 200 if result.success else 500,
                    "msg": result.error_msg if result.error_msg else "ä»»åŠ¡æ‰§è¡Œå®Œæˆ",
                    "data": result_dict,
                    "reward": reward_score,
                }
            )

        queued = any(task["request_id"] == request_id for task in task_queue)
        running = request_id in processing_requests

    if queued or running:
        return JSONResponse(
            status_code=202,
            content={
                "code": 202,
                "msg": "ä»»åŠ¡æ­£åœ¨æ‰§è¡Œï¼Œè¯·ç¨åæŸ¥è¯¢",
                "data": {"request_id": request_id}
            }
        )

    raise HTTPException(status_code=404, detail=f"è¯·æ±‚ID{request_id}ä¸å­˜åœ¨")


@app.post("/stop-all-processes")
async def stop_all_processes(
    x_api_key: str = Header(None, description="APIé‰´æƒKey")
):
    """ç»ˆæ­¢ç”±å½“å‰serverå¯åŠ¨å¹¶ä»åœ¨è¿è¡Œçš„æ‰€æœ‰è¿›ç¨‹"""
    if x_api_key != AUTH_API_KEY:
        raise HTTPException(status_code=401, detail="æœªæˆæƒï¼šAPI Keyé”™è¯¯")

    summary = stop_all_tracked_processes()
    return JSONResponse(
        status_code=200,
        content={
            "code": 200,
            "msg": "å·²å°è¯•åœæ­¢æ‰€æœ‰serverä¾§å·²è®°å½•çš„è¿›ç¨‹",
            "data": summary
        }
    )


@app.post("/start-random-workload")
async def start_random_workload(
    x_api_key: str = Header(None, description="APIé‰´æƒKey")
):
    """
    å†æ¬¡éšæœºå¯åŠ¨ä¸€æ‰¹benchmarkè´Ÿè½½ï¼Œå‚æ•°ä¸æœåŠ¡å¯åŠ¨æ—¶ä¸€è‡´ã€‚
    ä»»åŠ¡åœ¨åå°çº¿ç¨‹è¿è¡Œï¼Œç«‹å³è¿”å›ã€‚
    """
    if x_api_key != AUTH_API_KEY:
        raise HTTPException(status_code=401, detail="æœªæˆæƒï¼šAPI Keyé”™è¯¯")

    pids = trigger_random_workload_async(source="api")
    pid_msg = ",".join(str(pid) for pid in pids)
    return JSONResponse(
        status_code=200,
        content={
            "code": 200,
            "msg": pid_msg
        }
    )

@app.get("/baseline-sample")
async def baseline_sample(
    x_api_key: str = Header(None, description="APIé‰´æƒKey")
):
    """è¿”å›å½“å‰æœºå™¨çš„åˆå§‹ ps/lscpu + workload(pid) ç»´åº¦çš„ perf/top é‡‡æ ·ç»“æœ"""
    if x_api_key != AUTH_API_KEY:
        raise HTTPException(status_code=401, detail="æœªæˆæƒï¼šAPI Keyé”™è¯¯")
    samples = collect_baseline_sample()
    return JSONResponse(
        status_code=200,
        content={
            "code": 200,
            "msg": "åŸºçº¿é‡‡æ ·å®Œæˆ",
            "data": samples
        }
    )

# å¥åº·æ£€æŸ¥æ¥å£
@app.get("/health")
async def health_check():
    with queue_lock:
        queue_size = len(task_queue)
    return {
        "status": "ok",
        "service": "numa-bind-task-executor",
        "queue_size": queue_size,
        "is_processing": is_processing
    }

if __name__ == "__main__":
    import uvicorn
    # å¯åŠ¨FastAPIæœåŠ¡ï¼Œç›‘å¬æ‰€æœ‰ç½‘å¡
    uvicorn.run(app, host="0.0.0.0", port=8000)
